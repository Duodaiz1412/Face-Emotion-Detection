import gradio as gr
import numpy as np
import cv2
from keras.models import load_model

theme = gr.themes.Soft()

# T·∫£i m√¥ h√¨nh
model = load_model('emotion_model.h5')

# Nh√£n c·∫£m x√∫c
emotion_labels = ['Gi·∫≠n d·ªØ', 'Gh√™ t·ªüm', 'S·ª£ h√£i', 'H·∫°nh ph√∫c', 'B√¨nh th∆∞·ªùng', 'Bu·ªìn b√£', 'Ng·∫°c nhi√™n']
emotion_icons = ['üò°', 'ü§¢','üò±', 'üòä','üôÇ','üò≠','üòÆ']

def resize_image(image, max_size=500):
    height, width = image.shape[:2]
    if height > max_size or width > max_size:
        scale = max_size / max(height, width)
        new_size = (int(width * scale), int(height * scale))
        image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)
    return image

def predict_emotion(image):
    # Resize ·∫£nh cho preview
    preview_image = resize_image(image)

    # Ph√°t hi·ªán khu√¥n m·∫∑t
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5)

    print(f"S·ªë l∆∞·ª£ng khu√¥n m·∫∑t ph√°t hi·ªán: {len(faces)}")  # In ra s·ªë l∆∞·ª£ng khu√¥n m·∫∑t ph√°t hi·ªán

    if len(faces) == 0:
        return "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t", preview_image  # Tr·∫£ v·ªÅ h√¨nh ·∫£nh g·ªëc n·∫øu kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t

    # L·∫•y khu√¥n m·∫∑t ƒë·∫ßu ti√™n
    (x, y, w, h) = faces[0]
    face_image = gray_image[y:y+h, x:x+w]  # C·∫Øt khu√¥n m·∫∑t

    # V·∫Ω h√¨nh ch·ªØ nh·∫≠t quanh khu√¥n m·∫∑t tr√™n ·∫£nh g·ªëc
    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # V·∫Ω h√¨nh ch·ªØ nh·∫≠t m√†u xanh

    # Resize ·∫£nh g·ªëc ƒë√£ khoanh v√πng cho preview
    preview_image = resize_image(image)

    # Chuy·ªÉn ƒë·ªïi h√¨nh ·∫£nh th√†nh ƒë·ªãnh d·∫°ng m√† m√¥ h√¨nh c√≥ th·ªÉ x·ª≠ l√Ω
    face_image = cv2.resize(face_image, (48, 48))
    face_image = face_image.astype('float32') / 255.0
    face_image = face_image.reshape(1, 48, 48, 1)

    # D·ª± ƒëo√°n c·∫£m x√∫c
    prediction = model.predict(face_image)
    print(prediction)
    emotion_index = np.argmax(prediction)
    print(f"V·ªã tr√≠ c·ªßa c·∫£m x√∫c: {emotion_index + 1}")
    emotion = emotion_labels[emotion_index]
    icon = emotion_icons[emotion_index]
    return f"C·∫£m x√∫c khu√¥n m·∫∑t l√†: {emotion} {icon}", preview_image  # Tr·∫£ v·ªÅ c·∫£m x√∫c v√† h√¨nh ·∫£nh ƒë√£ khoanh v√πng

js = """
window.onload = function() {
        if (!window.location.href.includes('__theme=light')) {
            window.location.href = window.location.href + '?__theme=light';
        }
    }
"""

css = """
textarea {
    font-size: 20px;
}
body {
    background-color: white !important;
    color: black !important;
}
"""
# T·∫°o giao di·ªán Gradio v·ªõi CSS t√πy ch·ªânh
description_text = "·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng m√¥ h√¨nh CNN cho ph√©p ng∆∞·ªùi d√πng t·∫£i l√™n h√¨nh ·∫£nh khu√¥n m·∫∑t v√† d·ª± ƒëo√°n c·∫£m x√∫c c·ªßa ng∆∞·ªùi trong ·∫£nh.."

iface = gr.Interface(theme=theme,
                     fn=predict_emotion, 
                     inputs=gr.Image(type="numpy", label="T·∫£i l√™n h√¨nh ·∫£nh"),
                     outputs=[gr.Textbox(label="C·∫£m x√∫c d·ª± ƒëo√°n"), gr.Image(label="H√¨nh ·∫£nh ƒë√£ khoanh v√πng")],
                     title="D·ª± ƒëo√°n c·∫£m x√∫c khu√¥n m·∫∑t",
                     description=description_text,
                     css=css,
                     js=js
                     )  # Th√™m m√¥ t·∫£ cho ·ª©ng d·ª•ng

# Ch·∫°y ·ª©ng d·ª•ng
iface.launch()